{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1.post2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 基础操作\n",
    "从接口的角度来讲，对tensor的操作可分为两类：  \n",
    "\n",
    "torch.function，如torch.save等。  \n",
    "另一类是tensor.function，如tensor.view等。  \n",
    "而从存储的角度来讲，对tensor的操作又可分为两类：\n",
    "\n",
    "不会修改自身的数据，如 a.add(b)， 加法的结果会返回一个新的tensor。  \n",
    "会修改自身的数据，如 a.add_(b)， 加法的结果仍存储在a中，a被修改了。  \n",
    "函数名以_结尾的都是inplace方式, 即会修改调用者自己的数据，在实际应用中需加以区分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建Tensor\n",
    "\n",
    "创建的时候可以指定dtype  \n",
    "使用Tensor创建对象的时候不会立即分配内存空间，只是计算剩余空间是否足够分配\n",
    "\n",
    "函数|功能\n",
    "-|-\n",
    "Tensor(*size) | 基础构造函数，可以传入list或size\n",
    "tensor(data) | 类似ndarray的构造函数\n",
    "ones(*size) | 全1Tensor\n",
    "zeros(*size)| 全0Tensor\n",
    "eye(*size)| 对角线为1，其他为0\n",
    "arange(start, stop, step)| 从start到end， 步长为step , 前闭后开\n",
    "linspace(start, stop, steps)| 从start到end， 均匀分成steps份\n",
    "rand/randn(*size)| 均匀/标准分布\n",
    "normal(mean, std)/uniform(from, to)| 正态分布/均匀分布\n",
    "randperm(m)| \t随机排列 m数量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  3.6893e+19],\n",
       "        [ 7.7477e+27, -3.6902e+19],\n",
       "        [ 8.9751e+27,  2.5250e-29]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定Tensor的形状, 数值取决于内存空间的状态\n",
    "torch.Tensor(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用list数据创建Tensor\n",
    "b = torch.Tensor([[1, 2], [3, 4]])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 2.0], [3.0, 4.0]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把tensor转为list\n",
    "b.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor.size() == tensor.shape 返回torch.Size()对象，他是tuple的之类 \n",
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 元素总个数 == b.nelement()\n",
    "b.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  3.2500,  5.5000,  7.7500, 10.0000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(1, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6931, 0.4119],\n",
       "        [0.3536, 0.0743]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9071,  0.6642],\n",
       "        [ 0.7451, -0.6749]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 2, 6, 9, 3, 1, 5, 7, 4, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 常用Tensor操作\n",
    "* view 改变形状\n",
    "* squeeze 增加维度\n",
    "* unsqueeze 减少维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(0, 6)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当某一维为 -1 时会自动计算大小\n",
    "b = a.view(-1, 3)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 2]],\n",
       "\n",
       "        [[3, 4, 5]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b.unsqueeze(1)  # 在第1维（下标从0开始）上增加“１” \n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 2]],\n",
       "\n",
       "        [[3, 4, 5]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 等价于\n",
    "b[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 2]],\n",
       "\n",
       "        [[3, 4, 5]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.unsqueeze(-2)  # -2表示倒数第二个维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0, 1, 2],\n",
       "           [3, 4, 5]]]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b.view(1, 1, 1, 2, 3)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.squeeze()  # 把所有维度为1的压缩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 100,   2],\n",
       "        [  3,   4,   5]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1] = 100  # 修改a以后，b作为a的view也会修改\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resize是另一种可以用来修改大小的方式，但与view不同的是，它可以修改tensor的大小，view要求新的tensor元素数量和之前保持一致；超过原来的tensor会重新分配内存，小于旧的数据会保留"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 100,   2],\n",
       "        [  3,   4,   5]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 100,   2]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.resize_(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 100,   2]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[                  0,                 100,                   2],\n",
       "        [                  3,                   4,                   5],\n",
       "        [3761681295377708845, 3270510746666873185, 7005689387710689891]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.resize_(3, 3)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 索引操作\n",
    "与numpy类似，索引出来的结果与原tensor共享内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7264, -0.1432,  1.5816, -0.1663],\n",
       "        [ 0.7970, -0.3107,  0.0646, -1.2328],\n",
       "        [-0.3219,  1.2549, -0.2297,  1.1201]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3, 4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7264, -0.1432,  1.5816, -0.1663])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第0行\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7264,  0.7970, -0.3219])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第0列\n",
    "a[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1432)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第0行第2个元素\n",
    "a[0][1]\n",
    "#a[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1663)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第0行最后一个元素\n",
    "a[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7264, -0.1432,  1.5816, -0.1663],\n",
       "        [ 0.7970, -0.3107,  0.0646, -1.2328]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 前2行\n",
    "a[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7264, -0.1432],\n",
       "        [ 0.7970, -0.3107]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 前2行， 第0，1列\n",
    "a[:2, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7264, -0.1432]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:1, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7264, -0.1432])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.7264, -0.1432,  1.5816, -0.1663],\n",
       "         [ 0.7970, -0.3107,  0.0646, -1.2328],\n",
       "         [-0.3219,  1.2549, -0.2297,  1.1201]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# None类似于 np.newaxis, 为a新增了一个轴\n",
    "# 等价于 a.view(1, a.shape[0], a.shape[1])\n",
    "a[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[-1.7264]],\n",
       "\n",
       "          [[-0.1432]],\n",
       "\n",
       "          [[ 1.5816]],\n",
       "\n",
       "          [[-0.1663]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 0.7970]],\n",
       "\n",
       "          [[-0.3107]],\n",
       "\n",
       "          [[ 0.0646]],\n",
       "\n",
       "          [[-1.2328]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[-0.3219]],\n",
       "\n",
       "          [[ 1.2549]],\n",
       "\n",
       "          [[-0.2297]],\n",
       "\n",
       "          [[ 1.1201]]]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:, None, :, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 1, 0, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回一个 ByteTensor\n",
    "a > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5816, 1.2549, 1.1201])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 等价于 a.masked_select(a>1)\n",
    "a[a > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5816, 1.2549, 1.1201])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.masked_select(a>1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 常用选择函数\n",
    "函数|功能\n",
    "-|-|\n",
    "index_select(input, dim, index) | 在指定维度dim上选取，比如选取某些行、某些列\n",
    "masked_select(input, mask) | a[a>0],使用ByteTensor进行选取\n",
    "non_zero(input) | 非0元素的下标\n",
    "gather(input, dim, index) | 根据index，在dim维度上选取数据，输出的size与index一样\n",
    "\n",
    "gather是一个比较复杂的操作，对一个2维tensor，输出的每个元素如下：\n",
    "```python\n",
    "out[i][j] = input[index[i][j]][j]  # dim=0\n",
    "out[i][j] = input[i][index[i][j]]  # dim=1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(0, 16).view(4, 4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  5, 10, 15]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选取对角线的元素\n",
    "index = torch.LongTensor([[0, 1, 2, 3]])\n",
    "a.gather(0, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3],\n",
       "        [ 6],\n",
       "        [ 9],\n",
       "        [12]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选取反对角线上的元素\n",
    "index = torch.LongTensor([[3, 2, 1, 0]]).t()\n",
    "a.gather(1, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor 类型\n",
    "各类型之间可以相互转换， type(new_type)是通用做法，默认的tensor是 FloatTensor    \n",
    "\n",
    "\n",
    "Data Type | dtype | CPU tensor | GPU tensor  \n",
    "-|-|-|-|\n",
    "32-bit floating point | torch.float32 or torch.float | torch.FloatTensor | torch.cuda.FloatTensor\n",
    "64-bit floating point | torch.float64 or torch.double | torch.DoubleTensor | torch.cuda.DoubleTensor\n",
    "16-bit floating point | torch.float16 or torch.half | torch.HalfTensor | torch.cuda.HalfTensor\n",
    "8-bit interger(unsigned) | torch.uint8 | torch.ByteTensor | torch.cuda.ByteTensor\n",
    "8-bit integer(signed) | torch.int8 | torch.CharTensor | torch.cuda.CharTensor\n",
    "16-bit integer (signed) | torch.int16 or torch.short | torch.ShortTensor | torch.cuda.ShortTensor\n",
    "32-bit integer(signed) | torch.int32 or torch.int | torch.IntTensor | torch.cuda.IntTensor\n",
    "64-bit integer(signed) | torch.int64 or torch.long | torch.LongTensor | torch.cuda.LongTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置默认参数类型\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.6816e+154,   2.0039e+00,  1.4822e-323],\n",
       "        [  0.0000e+00, -1.4946e-154,  4.2153e-309]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(2, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把a转成FloatTensor\n",
    "b = a.float()\n",
    "b.dtype\n",
    "\n",
    "#b = a.type(torch.FloatTensor)\n",
    "#b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.type_as(b)\n",
    "c.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 逐元素操作\n",
    "对tensor的每一个元素(point-wise, 又名element-wise)进行操作，此类操作的输入与输出形状一致  \n",
    "\n",
    "\n",
    "函数|功能\n",
    "-|-|\n",
    "abs/sqrt/div/exp/fmod/log/pow..|绝对值/平方根/除法/指数/求余..\n",
    "cos/sin/asin/atan2/cosh.. | 相关三角函数\n",
    "ceil/round/floor/trunc|向上取整/四舍五入/向下取整/截断\n",
    "clamp(input, min, max)|超过min和max部分截断\n",
    "sigmod/tanh..|激活函数\n",
    "\n",
    "其中clamp(x, min, max)的输出满足以下公式：\n",
    "$$\n",
    "y_i = \n",
    "\\begin{cases}\n",
    "    min, \\quad if\\quad x_i \\lt min \\\\\n",
    "    x_i, \\quad\\quad if\\quad min \\leq x_i \\leq max \\\\\n",
    "    max, \\quad if\\quad x_i \\gt max\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(0, 6).view(2, 3)\n",
    "a = a.type(torch.FloatTensor)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.5403, -0.4161],\n",
       "        [-0.9900, -0.6536,  0.2837]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cos(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [0., 1., 2.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [0., 1., 2.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.fmod(a, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clamp(a, min=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 归并操作\n",
    "此类操作会使输出形状小于输入形状，并可以沿着某一维度进行指定操作\n",
    "常用归并操作：\n",
    "\n",
    "函数|功能\n",
    "-|-\n",
    "mean/sum/median/mode | 均值/和/中位数/众数\n",
    "norm/dist | 范数/距离\n",
    "std/var | 标准差/方差\n",
    "cumsum/cumprod | 累加/累乘\n",
    "\n",
    "假设输入的形状是(m, n, k)\n",
    "\n",
    "如果指定dim=0，输出的形状就是(1, n, k)或者(n, k)\n",
    "如果指定dim=1，输出的形状就是(m, 1, k)或者(m, k)\n",
    "如果指定dim=2，输出的形状就是(m, n, 1)或者(m, n)\n",
    "size中是否有\"1\"，取决于参数keepdim，keepdim=True会保留维度1。注意，以上只是经验总结，并非所有函数都符合这种形状变化方式，如cumsum。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.ones(2, 3)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sum(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3.])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(0, 6).view(2, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  3],\n",
       "        [ 3,  7, 12]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.cumsum(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 比较\n",
    "常用比较运算符已经重载\n",
    "\n",
    "函数|功能\n",
    "-|-\n",
    "gt/lt/ge/le/eq/ne | 大于/小于/大于等于/小于等于/等于/不等\n",
    "topk | 最大的k个数\n",
    "sort | 排序\n",
    "max/min | 比较两个tensor最大最小值\n",
    "\n",
    "第一行返回结果是一个 ByteTensor,可用来选取元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  3.,  6.],\n",
       "        [ 9., 12., 15.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.linspace(0, 15, 6).view(2, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15., 12.,  9.],\n",
       "        [ 6.,  3.,  0.]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.linspace(15, 0, 6).view(2, 3)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a > b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 12., 15.])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a>b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 6., 15.]), tensor([2, 2]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(a, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线性代数\n",
    "函数|功能\n",
    "-|-\n",
    "trace | 对角线元素之和(矩阵的迹)\n",
    "diag | 对角线元素\n",
    "triu/tril | 矩阵的上三角/下三角，可指定偏移量\n",
    "mm/bmm | 矩阵乘法，batch的矩阵乘法\n",
    "addmm/addbmm/addmv/addr/badbmm.. | 矩阵运算 \n",
    "t | 转置\n",
    "dot/cross | 内积/外积\n",
    "inverse | 求逆矩阵\n",
    "svd | 奇异值分解\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  3.,  6.],\n",
       "        [ 9., 12., 15.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  9.],\n",
       "        [ 3., 12.],\n",
       "        [ 6., 15.]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor和Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones([2, 3], dtype=np.float32)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.Tensor(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意：** 当numpy的数据类型和tensor的类型不一样时，数据会被复制，不会共享内存  \n",
    "**注意：** 不论输入的类型是什么，torch.tensor都会进行数据拷贝，不会共享内存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch手动实现广播机制\n",
    "* unsqueeze或者view，或者tensor[None]:为数据某一维的形状补1\n",
    "* expand或者expand_as，重复数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(3, 2)\n",
    "b = torch.zeros(2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a的维度小于b，现在a的前边广播扩展为 (1, 3, 2)\n",
    "# 扩展a第一维 (2, 3, 2)\n",
    "# 扩展b第三维 (2, 3, 2)\n",
    "# 广播扩展成功\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 手动实现广播\n",
    "a.unsqueeze(0).expand(2, 3, 2) + b.expand(2, 3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor数据结构\n",
    "tensor分为头信息区和存储区(Storage)，信息区主要保存着tensor的形状(size)、步长(stride)、数据类型(dtype)等信息。而真正的数据则保存成连续数组  \n",
    "一般来说一个tensor有着与之对应的storage，storage是在data上封装的接口，便于使用，而不同的tensor都信息一般不同，但却可能使用相同的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       "[torch.LongStorage of size 6]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(6)\n",
    "a.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       "[torch.LongStorage of size 6]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.view(2, 3)\n",
    "b.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一个对象的id值可以看做它在内存中的地址\n",
    "# storage的内存地址一样，即是同一个storage\n",
    "id(b.storage()) == id(a.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 100,   2],\n",
       "        [  3,   4,   5]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 改变a，b也随之改变，因为他们共享storage\n",
    "a[1] = 100\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 100\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       "[torch.LongStorage of size 6]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a[2:]\n",
    "c.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140217204155680, 140217204155664)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.data_ptr(), a.data_ptr()  # data_ptr返回tensor首元素的内存地址"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU/CPU\n",
    "使用tensor.cuda(device_id)或者tensor.cpu()。更通用的方法 tensor.to(device)  \n",
    "尽量使用tensor.to(device),将device设置为一个可配置的参数，这样可以是程序很轻松的兼容GPU/CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3, 4)\n",
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    a = torch.randn(3, 4, device=torch.device('cuda:1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向量化\n",
    "向量化计算是一种特殊的并行计算方式，相对于一般程序在同一时间只执行一个操作的方式，它可在同一时间执行多个操作，通常是不同的数据执行同样的一个或一批指令，或者说把指令应用于一个数组/或向量上。  \n",
    "在科学计算中，应避免使用Python的for循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_loop_add(x, y):\n",
    "    result = []\n",
    "    for i, j in zip(x, y):\n",
    "        result.append(i + j)\n",
    "    return torch.Tensor(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851 µs ± 131 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "The slowest run took 11.44 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "7.99 µs ± 11.4 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(100)\n",
    "y = torch.ones(100)\n",
    "%timeit -n 10 for_loop_add(x, y)\n",
    "%timeit -n 10 x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 小试牛刀：线性回归\n",
    "$$loss = \\sum_i^N{\\frac{1}{2}(y_i - (wx_i + b))^2}$$\n",
    "利用随机梯度下降更新参数 w和b 来最小化损失函数，最终学到w和b的数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10e408cf0>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置随机数种子，保证在不同电脑上运行时下面输出一致\n",
    "torch.manual_seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fake_data(batch_size=8):\n",
    "    \"\"\"产生随机数据y = x*2 + 3,加了一些噪声\"\"\"\n",
    "    x = torch.rand(batch_size, 1, device=device) * 5\n",
    "    y = x * 2 + 3 + torch.randn(batch_size, 1, device=device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x122eb2ba8>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD9CAYAAACsq4z3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADthJREFUeJzt3V9oZOd9xvHniaw2402LUqyUrNbuuqXIDXYbtUNwu9AWO66WxDiLyYVNHdzEsBRK65RUrkUuTK+8oJKmVwVhuw7EbC4cVS0JrbJkbUzBcardsaN1ZCXQOu7OOl0ZoyZth0aWf73QyPVqJc2fc2bOmXe+HxCSXp2d98eBfTi8/44jQgCAwfeeogsAAOSDQAeARBDoAJAIAh0AEkGgA0AiCHQASETLQLf9hO3Lti/s8bc/sx22r+tNeQCAdrXzhP6kpOO7G21fL+kOSa/lXBMAoAstAz0inpP05h5/+itJD0liZxIAlEBXY+i275JUj4iXcq4HANClazr9B7avlfR5Sb/X5vUnJZ2UpEOHDv3GTTfd1GmXADDUzp0790ZEjLe6ruNAl/RLkm6U9JJtSToi6bztj0TED3dfHBHzkuYlqVqtxvLychddAsDwsv2Ddq7rONAjYkXSB97V0auSqhHxRqefBQDITzvLFk9Lel7SpO2Lth/ofVkAgE61fEKPiHtb/P1obtUAALrGTlEASASBDgCJ6GaVCwCgDYu1uuaW1nRpo6HDYxXNTE/qxNREz/oj0AGgBxZrdc0urKixuSVJqm80NLuwIkk9C3WGXACgB+aW1t4J8x2NzS3NLa31rE8CHQB64NJGo6P2PBDoANADh8cqHbXngUAHgB6YmZ5UZXTkirbK6Ihmpid71ieTogDQAzsTn6xyAYAEnJia6GmA78aQCwAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIBIEOAIloGei2n7B92faFd7XN2X7F9nds/53tsd6WCQBopZ0n9CclHd/VdkbSzRHxq5K+J2k257oAAB1qGegR8ZykN3e1fSMi3mr++i1JR3pQGwCgA3mMoX9G0j/m8DkAgAwyBbrtz0t6S9JTB1xz0vay7eX19fUs3QEADtB1oNu+X9Kdkn4/ImK/6yJiPiKqEVEdHx/vtjsAQAvXdPOPbB+X9OeSfici/iffkgCkYrFW19zSmi5tNHR4rKKZ6UmdmJoouqxktQx026cl/a6k62xflPSItle1/LSkM7Yl6VsR8Yc9rBPAgFms1TW7sKLG5pYkqb7R0OzCiiQR6j3SMtAj4t49mh/vQS0AEjK3tPZOmO9obG5pbmmNQO8RdooC6IlLG42O2pEdgQ6gJw6PVTpqR3YEOoCemJmeVGV05Iq2yuiIZqYne9bnYq2uY6fO6saHv65jp85qsVbvWV9l1NUqFwBoZWecvF+rXJiEJdAB9NCJqYm+hSmTsAy5AEgEk7AEOoBEMAlLoANIRBGTsGXDGDqAJPR7EraMCHQAyejnJGwZMeQCAIkg0AEgEQQ6ACSCQAeARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJINABIBEEOgAkgkAHgEQQ6ACQCAIdABJBoANAIloGuu0nbF+2feFdbT9n+4zt7ze/v7+3ZQIAWmnnCf1JScd3tT0s6ZsR8cuSvtn8HQBQoJaBHhHPSXpzV/MnJH2p+fOXJJ3IuS4AQIe6HUP/+Yh4XZKa3z+QX0kAgG70/J2itk9KOilJN9xwQ6+7A9ClxVp9qF+wnIJun9D/w/YHJan5/fJ+F0bEfERUI6I6Pj7eZXcAemmxVtfsworqGw2FpPpGQ7MLK1qs1YsuDR3oNtD/QdL9zZ/vl/T3+ZQDoAhzS2tqbG5d0dbY3NLc0lpBFaEb7SxbPC3peUmTti/afkDSKUl32P6+pDuavwMYUJc2Gh21o5xajqFHxL37/On2nGsBUIDFWl3vsbUVcdXfDo9VCqgI3WKnKDDEdsbO9wrzyuiIZqYnC6gK3SLQgSG219i5JI3YevTuW1jlMmAIdGCI7TdG/nYEYT6ACHRgiO03Rs7Y+WAi0IEhNjM9qcroyBVtjJ0Prp7vFAVQXjvDKuwQTQOBDgy5E1MTBHgiGHIBgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARBDoAJCITIFu+09tv2z7gu3Ttt+bV2EAgM50Hei2JyT9iaRqRNwsaUTSPXkVBgDoTNaXRF8jqWJ7U9K1ki5lLwmpWKzVeZs80EddP6FHRF3SX0p6TdLrkv4zIr6RV2EYbIu1umYXVlTfaCgk1Tcaml1Y0WKtXnRpQLKyDLm8X9InJN0o6bCkQ7bv2+O6k7aXbS+vr693XykGytzSmhqbW1e0NTa3NLe0VlBFQPqyTIp+VNK/RcR6RGxKWpD0W7svioj5iKhGRHV8fDxDdxgklzYaHbUDyC5LoL8m6Vbb19q2pNslreZTFgbd4bFKR+0Asssyhv6CpKclnZe00vys+ZzqwoCbmZ5UZXTkirbK6IhmpicLqghIX6ZVLhHxiKRHcqoFCdlZzcIqF6B/si5bBPZ1YmqCAAf6iK3/AJAIAh0AEkGgA0AiCHQASASTohganC2D1BHoGAo7Z8vsHEewc7aMJEIdyWDIBUOBs2UwDAh0DAXOlsEwINAxFDhbBsOAQMdQ4GwZDAMmRUuEVRh7y+O+cLYMhgGBXhKswthbnveFs2WQOoZcSoJVGHvjvgDtI9BLglUYe+O+AO0j0EuCVRh7474A7SPQS4JVGHvjvgDtY1K0JFiFsTfuC9A+R0TfOqtWq7G8vNy3/gAgBbbPRUS11XU8oeNArI0HBgeBjn11ugac8AeKxaQo9tXJGvCd8K9vNBT6//BfrNX7VC0AAh376mQNOBuAgOIR6NhXJ2vA2QAEFI9Ax746WQPOBiCgeJkC3faY7adtv2J71fZv5lUYindiakKP3n2LJsYqsqSJsYoevfuWPSc62QAEFC/rKpe/lvRPEfFJ2z8l6docakKJtHtCIRuAgOJ1Hei2f1bSb0v6A0mKiJ9I+kk+ZWEQcTwtUKwsQy6/KGld0t/artl+zPahnOoCAHQoS6BfI+nXJf1NRExJ+m9JD+++yPZJ28u2l9fX1zN0h04t1uo6duqsbnz46zp26ixrwoHEZQn0i5IuRsQLzd+f1nbAXyEi5iOiGhHV8fHxDN2hE2z0AYZP14EeET+U9O+2d5Yx3C7pu7lUhczY6AMMn6yrXP5Y0lPNFS7/KunT2UtCHtjoAwyfTIEeES9KanmkI/rv8FhF9T3Cm40+QLrYKZooNvoAw4fjcxPFRh9g+BDoCWOjDzBcGHIBgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BEsFM0B4u1OlvsARSOQM9o50USO2eP77xIQhKhDqCvGHLJiBdJACgLAj0jXiQBoCwI9Iz2e2EEL5IA0G8Eeka8SAJAWTApmhEvkgBQFgR6DniRBIAyYMgFABJBoANAIgh0AEgEgQ4AiSDQASARmQPd9ojtmu2v5VEQAKA7eTyhPyhpNYfPAQBkkCnQbR+R9HFJj+VTDgCgW1mf0L8o6SFJb+dQCwAgg64D3fadki5HxLkW1520vWx7eX19vdvuAAAtZHlCPybpLtuvSvqKpNtsf3n3RRExHxHViKiOj49n6A4AcJCuAz0iZiPiSEQclXSPpLMRcV9ulQEAOsI6dABIRC6nLUbEs5KezeOzAADd4QkdABJBoANAIgh0AEgEgQ4AiSDQASARyb1TdLFW54XNAIZSUoG+WKtrdmFFjc0tSVJ9o6HZhRVJItQBJC+pIZe5pbV3wnxHY3NLc0trBVUEAP2TVKBf2mh01A4AKUkq0A+PVTpqB4CUJBXoM9OTqoyOXNFWGR3RzPRkQRUBQP8kNSm6M/HJKhcAwyipQJe2Q50ABzCMkhpyAYBhRqADQCIIdABIBIEOAIkYiElRzmcBgNZKH+iczwIA7Sn9kAvnswBAe0of6JzPAgDtKX2gcz4LALSn9IHO+SwA0J7ST4pyPgsAtKf0gS5xPgsAtKPrIRfb19t+xvaq7ZdtP5hnYQCAzmR5Qn9L0uci4rztn5F0zvaZiPhuTrUBADrQ9RN6RLweEeebP/9Y0qokxkUAoCC5rHKxfVTSlKQX8vg8AEDnMge67fdJ+qqkz0bEj/b4+0nby7aX19fXs3YHANhHplUutke1HeZPRcTCXtdExLykeUmqVquRpT8O6QKA/XUd6LYt6XFJqxHxhfxK2huHdAHAwbIMuRyT9ClJt9l+sfn1sZzqugqHdAHAwbp+Qo+If5bkHGs5EId0AcDBSn+Wyw4O6QKAgw1MoHNIFwAcbCDOcpE4pAsAWhmYQJc4pAsADjIwQy4AgIMR6ACQCAIdABJBoANAIgh0AEiEIzKdl9VZZ/a6pB/0rcPyuE7SG0UXUTLck6txT67GPdn2CxEx3uqivgb6sLK9HBHVousoE+7J1bgnV+OedIYhFwBIBIEOAIkg0PtjvugCSoh7cjXuydW4Jx1gDB0AEsETOgAkgkDvEdtP2L5s+0LRtZSF7ettP2N71fbLth8suqYysP1e29+2/VLzvvxF0TWVhe0R2zXbXyu6lkFAoPfOk5KOF11Eybwl6XMR8SuSbpX0R7Y/VHBNZfC/km6LiF+T9GFJx23fWnBNZfGgpNWiixgUBHqPRMRzkt4suo4yiYjXI+J88+cfa/s/6tCfhxzb/qv562jza+gnt2wfkfRxSY8VXcugINBRCNtHJU1JeqHYSsqhObTwoqTLks5EBPdF+qKkhyS9XXQhg4JAR9/Zfp+kr0r6bET8qOh6yiAitiLiw5KOSPqI7ZuLrqlItu+UdDkizhVdyyAh0NFXtke1HeZPRcRC0fWUTURsSHpWzL8ck3SX7VclfUXSbba/XGxJ5Uego29sW9LjklYj4gtF11MWtsdtjzV/rkj6qKRXiq2qWBExGxFHIuKopHsknY2I+wouq/QI9B6xfVrS85ImbV+0/UDRNZXAMUmf0vbT1ovNr48VXVQJfFDSM7a/I+lftD2GzjI9dIydogCQCJ7QASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIBIEOAIn4PxlQNWNFqsmzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = get_fake_data(batch_size=16)\n",
    "# plt.scatter(x.squeeze().cpu().numpy(), y.squeeze().cpu().numpy())\n",
    "plt.scatter(x.squeeze(), y.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3], [1, 2, 3]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 5, 6],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([[4, 5, 6], [4, 5, 6]])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 4],\n",
       "        [5, 5],\n",
       "        [6, 6]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b.t()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[32, 32], [32, 32]]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[4+10+18, 32],\n",
    " [32, 32]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32, 32],\n",
       "        [32, 32]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(a, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  1.9908932447433472 b:  2.931361675262451\n"
     ]
    }
   ],
   "source": [
    "# 随机初始化参数\n",
    "w = torch.rand(1, 1).to(device)\n",
    "b = torch.zeros(1, 1).to(device)\n",
    "\n",
    "lr =0.02 # 学习率\n",
    "\n",
    "for ii in range(500):\n",
    "    x, y = get_fake_data(batch_size=4)\n",
    "    \n",
    "    # forward：计算loss\n",
    "    y_pred = x.mm(w) + b.expand_as(y) # x@W等价于x.mm(w);for python3 only\n",
    "    loss = 0.5 * (y_pred - y) ** 2 # 均方误差\n",
    "    loss = loss.mean()\n",
    "    \n",
    "    # backward：手动计算梯度\n",
    "    dloss = 1\n",
    "    dy_pred = dloss * (y_pred - y)\n",
    "    \n",
    "    dw = x.t().mm(dy_pred)\n",
    "    db = dy_pred.sum()\n",
    "    \n",
    "    # 更新参数\n",
    "    w.sub_(lr * dw)\n",
    "    b.sub_(lr * db)\n",
    "    \n",
    "    if ii%50 ==0:\n",
    "       \n",
    "        # 画图\n",
    "        display.clear_output(wait=True)\n",
    "        x = torch.arange(0, 6, dtype=torch.float).view(-1, 1)\n",
    "        y = x.mm(w) + b.expand_as(x)\n",
    "        plt.plot(x.cpu().numpy(), y.cpu().numpy()) # predicted\n",
    "        \n",
    "        x2, y2 = get_fake_data(batch_size=32) \n",
    "        plt.scatter(x2.numpy(), y2.numpy()) # true data\n",
    "        \n",
    "        plt.xlim(0, 5)\n",
    "        plt.ylim(0, 13)\n",
    "        plt.show()\n",
    "        plt.pause(0.5)\n",
    "        \n",
    "print('w: ', w.item(), 'b: ', b.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1.post2'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
